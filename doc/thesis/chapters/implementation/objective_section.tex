
\section{Objective}\label{sec:objective}
The objective of this project is to present a novel approach for website administrators to detect web bots.
Supervised learning is a common ML approach to detect web bots.
In fact, most ML approaches to robot detection apply supervised learning~\cite{10.1145/3339252.3339267}.
This sort of approach consists of training a classifier, i.e.
a function mapping an input, which are usually feature vectors describing sessions, to an output, a sessionâ€™s class labels, based on a training dataset, which includes labelled training samples.
The ability of the inferred function to determine correct class labels for new, unseen samples is assessed on a test dataset.
Many supervised learning techniques demonstrated their efficiency in classification of bots and humans, e.g., decision trees support vector machine, neural networks , and k-Nearest Neighbours.
All supervised learning approaches, however, share a common disadvantage, related to a difficulty with preparation of a reliable training dataset, in particular with assigning accurate class labels to sessions of camouflaged robots~\cite{ROVETTA2020102577}.
In conclusion, since web bots are increasing in sophistication, meaning they are behaving more like humans in terms of mouse and HTTP request behavior~\cite{10.1109/DSN.2013.6575366}~\cite{7371507}, obtaining accurate training data that represents such complex web bots has been an issue.
This, combined with the anonymity of proxies that scramble the IP addresses of web bots, has motivated this project.

